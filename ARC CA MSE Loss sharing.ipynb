{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from evostra import EvolutionStrategy\n",
    "from evostra.models import FeedForwardNetwork\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'abstraction-and-reasoning-challenge\\\\training\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '0ca9ddb6.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(directory+filename, \"r\")\n",
    "data = f.readlines()\n",
    "print(len(data))\n",
    "data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = json.loads(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class big_NN(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(big_NN, self).__init__()\n",
    "        temp = num_channels*3\n",
    "        self.fc1 = nn.Linear(temp, temp)\n",
    "        self.fc2 = nn.Linear(temp, temp)\n",
    "        self.fc3 = nn.Linear(temp, num_channels)\n",
    "        self.fc4 = nn.Sigmoid()\n",
    "        #self.fc4 = nn.LeakyReLU()\n",
    "        \n",
    "        self.m1 = nn.Dropout(p=.01)\n",
    "        self.m2 = nn.Dropout(p=.01)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x1 = self.fc4(self.fc1(x))\n",
    "        x2 = self.fc4(self.fc3(x))\n",
    "        #x3 = self.fc4(self.fc3(x2))\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class out_height_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(out_height_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class out_width_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(out_width_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_state(trial_num,res,inp_channels):\n",
    "    inp_set = [c_num for c_num in range(10)]\n",
    "    \n",
    "    height = len(res['train'][trial_num]['input']) \n",
    "    width = len(res['train'][trial_num]['input'][0])\n",
    "    \n",
    "    inp_list = res['train'][trial_num]['input']\n",
    "    \n",
    "    inp_state = torch.zeros((inp_channels,height,width))\n",
    "    \n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            num = inp_list[row][col]\n",
    "            index = inp_set.index(num)\n",
    "            inp_state[index][row][col] = 1\n",
    "            \n",
    "    temp_alive = torch.zeros((1,height,width))\n",
    "    for i in range(1,inp_channels):\n",
    "        temp_alive = temp_alive + inp_state[i]\n",
    "        \n",
    "    inp_state[inp_channels-1] = temp_alive\n",
    "            \n",
    "    return inp_state,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ran_init_state(i,res,inp_channels):\n",
    "    \n",
    "    inp_set = [i for i in range(10)]\n",
    "    num_vals = 11\n",
    "    \n",
    "    height = len(res['train'][i]['output']) \n",
    "    width = len(res['train'][i]['output'][0])\n",
    "    \n",
    "    inp_list = res['train'][i]['output']\n",
    "    \n",
    "    inp_state = torch.rand((inp_channels,height,width))*.3\n",
    "    \n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            num = inp_list[row][col]\n",
    "            index = inp_set.index(num)\n",
    "            inp_state[index][row][col] = 1\n",
    "            \n",
    "    temp_alive = torch.zeros((1,height,width))\n",
    "    for i in range(1,inp_channels):\n",
    "        temp_alive = temp_alive + inp_state[i]\n",
    "        \n",
    "    inp_state[inp_channels-1] = temp_alive\n",
    "            \n",
    "    return inp_state,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_state(i,res,out_channels):\n",
    "    \n",
    "    inp_set = [i for i in range(10)]\n",
    "    \n",
    "    height = len(res['train'][i]['output']) \n",
    "    width = len(res['train'][i]['output'][0])\n",
    "    \n",
    "    inp_list = res['train'][i]['output']\n",
    "    \n",
    "    inp_state = torch.zeros((out_channels,height,width))\n",
    "    \n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            num = inp_list[row][col]\n",
    "            index = inp_set.index(num)\n",
    "            inp_state[index][row][col] = 1\n",
    "       \n",
    "    #get one-hot list of all colors that are 'on'\n",
    "    temp_alive = torch.zeros((1,height,width))\n",
    "    for i in range(1,out_channels):\n",
    "        temp_alive = temp_alive + inp_state[i]\n",
    "        \n",
    "    inp_state[-1] = temp_alive\n",
    "            \n",
    "    return inp_state,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perception(state,num_channels):\n",
    "    sobel_x = torch.FloatTensor([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "    sobel_y = torch.transpose(sobel_x,0,1)\n",
    "    \n",
    "    sobel_x = sobel_x.view(1,1,3,3)\n",
    "    sobel_y = sobel_y.view(1,1,3,3)\n",
    "    \n",
    "    big_state = F.pad(state,(1,1,1,1),\"constant\",0)\n",
    "    \n",
    "    grad_x = F.conv2d(big_state, sobel_x,stride=1,padding=0)\n",
    "    grad_y = F.conv2d(big_state, sobel_y,stride=1,padding=0)\n",
    "    temp_state = torch.cat((state,grad_x,grad_y),0)\n",
    "    \n",
    "    return temp_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(state_inp,num_channels,out_height,out_width,inp_height,inp_width,inp_channels):\n",
    "    state = torch.zeros((num_channels,1,out_height,out_width))\n",
    "    \n",
    "    #pad state input\n",
    "    height_dif = out_height - inp_height\n",
    "    width_dif = out_width - inp_width\n",
    "    state_inp = state_inp.view(inp_channels,1,inp_height,inp_width)\n",
    "    state_inp = F.pad(state_inp,(0,width_dif,0,height_dif),\"constant\",0)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_update(state,state_update,inp_channels,out_height,out_width,out_channels):\n",
    "    #blur_state = F.max_pool2d(state[inp_channels],kernel_size=3,stride=1,padding=1)\n",
    "    #alive = torch.where((blur_state>.1),torch.ones((num_channels,1,out_height,out_width)),torch.zeros((num_channels,1,out_height,out_width)))\n",
    "    #new_state = state + state_update*alive + torch.normal(0, .02, size=state.shape)\n",
    "    new_state = state + state_update + torch.normal(0, .02, size=state.shape)\n",
    "    \n",
    "    #print(\"state: {}  state_update: {}\".format(state.shape,state_update.shape))\n",
    "    \n",
    "    #original state inputs shouldn't change\n",
    "    for i in range(inp_channels):\n",
    "        new_state[i] = state[i]\n",
    "        \n",
    "    #multiply output channels by predicted \n",
    "    pred_sum_out_channels = torch.round(state[-1])\n",
    "    #pred_sum_out_channels = state[-1]\n",
    "    for i in range(num_channels-out_channels,num_channels-1):\n",
    "        new_state[i] = state[i]*pred_sum_out_channels\n",
    "    \n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_out_pred(res,file_num,epochs):\n",
    "    \n",
    "    height_model = out_height_model()\n",
    "    width_model = out_width_model()\n",
    "    \n",
    "    height_optimizer = optim.Adam(height_model.parameters(), lr=0.01)\n",
    "    width_optimizer = optim.Adam(width_model.parameters(), lr=0.01)\n",
    "    \n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        tot_loss1 = 0\n",
    "        tot_loss2 = 0\n",
    "        for trial in range(len(res['train'])):\n",
    "            height_optimizer.zero_grad()\n",
    "            height_model.zero_grad()\n",
    "\n",
    "            width_optimizer.zero_grad()\n",
    "            width_model.zero_grad()\n",
    "\n",
    "            state_inp,inp_height,inp_width = get_inp_state(trial,res,inp_channels)\n",
    "            state_out,out_height,out_width = get_out_state(trial,res,inp_channels)\n",
    "\n",
    "            inp_height = torch.FloatTensor([inp_height])\n",
    "            inp_width = torch.FloatTensor([inp_width])\n",
    "\n",
    "            out_height = torch.FloatTensor([out_height])\n",
    "            out_width = torch.FloatTensor([out_width])\n",
    "\n",
    "            out_height_pred = height_model(inp_height)\n",
    "            out_width_pred = width_model(inp_width)\n",
    "\n",
    "            loss1 = mse(out_height_pred,out_height)\n",
    "            loss2 = mse(out_width_pred,out_width)\n",
    "\n",
    "            loss1.backward()\n",
    "            loss2.backward()\n",
    "\n",
    "            height_optimizer.step()\n",
    "            width_optimizer.step()\n",
    "            tot_loss1+=loss1\n",
    "            tot_loss2+=loss2\n",
    "        if(tot_loss1<.0001 and tot_loss2<.0001):\n",
    "            break\n",
    "            #print(\"True out height: {}  Pred out height: {}\".format(out_height,out_height_pred))\n",
    "            #print(\"True out width: {}  Pred out width: {}\".format(out_width,out_width_pred))\n",
    "        \n",
    "    PATH1 = \"models\\\\\"+str(file_num)+\"_height_model.pt\"\n",
    "    PATH2 = \"models\\\\\"+str(file_num)+\"_width_model.pt\"\n",
    "    # Save\n",
    "    torch.save(height_model, PATH1)\n",
    "    torch.save(width_model, PATH2)\n",
    "        \n",
    "    return tot_loss1,tot_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(res,file_num):\n",
    "    \n",
    "    global steps, num_channels, inp_channels, tau, model, optimizer\n",
    "    \n",
    "    PATH1 = \"models\\\\\"+str(file_num)+\"_height_model.pt\"\n",
    "    PATH2 = \"models\\\\\"+str(file_num)+\"_width_model.pt\"\n",
    "    \n",
    "    height_model = torch.load(PATH1)\n",
    "    width_model = torch.load(PATH2)\n",
    "    \n",
    "    mse = nn.MSELoss()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_list = []\n",
    "    tot_loss = 0\n",
    "    for trial in range(len(res['train'])):\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        temp_choice = np.random.choice([0,1],1,p=[1.0,0.0])\n",
    "        temp_dict = {0: get_inp_state,1: get_ran_init_state}\n",
    "        \n",
    "        state_inp,inp_height,inp_width = temp_dict[temp_choice[0]](trial,res,inp_channels)\n",
    "        \n",
    "        #get predicted output height\n",
    "        inp_height_tensor = torch.FloatTensor([inp_height])\n",
    "        out_height = torch.round(height_model(inp_height_tensor))\n",
    "        out_height = int(out_height)\n",
    "        \n",
    "        #get predicted output width\n",
    "        inp_width_tensor = torch.FloatTensor([inp_width])\n",
    "        out_width = torch.round(width_model(inp_width_tensor))\n",
    "        out_width = int(out_width)\n",
    "        \n",
    "        num_inp = out_height*out_width\n",
    "        \n",
    "        #run \n",
    "        state_inp = torch.FloatTensor(state_inp)\n",
    "        temp_state = init_state(state_inp,num_channels,out_height,out_width,inp_height,inp_width,inp_channels)\n",
    "        for step in range(steps):\n",
    "            net_inp = perception(temp_state,num_channels-inp_channels)\n",
    "            net_inp = torch.transpose(net_inp, 0, 3)\n",
    "            net_inp = torch.transpose(net_inp, 1, 2)\n",
    "            net_inp = net_inp.reshape((num_inp,num_channels*3))\n",
    "\n",
    "            state_update = model(net_inp)\n",
    "\n",
    "            state_update = state_update.view((out_width,out_height,1,num_channels))\n",
    "            state_update = torch.transpose(state_update, 1, 2)\n",
    "            state_update = torch.transpose(state_update, 0, 3)\n",
    "            state_update = stochastic_update(temp_state,state_update,inp_channels,out_height,out_width,out_channels)\n",
    "            temp_state = state_update\n",
    "            \n",
    "            #multiple predicted output by all output squares\n",
    "            \n",
    "        #get losses\n",
    "        true_out_state,out_height,out_width = get_out_state(trial,res,out_channels)\n",
    "        true_out_state = torch.FloatTensor(true_out_state)\n",
    "\n",
    "        pred_out_state = temp_state[num_channels-out_channels:num_channels].view(out_channels,out_height,out_width)\n",
    "        pred_out_state = F.softmax(pred_out_state,0)\n",
    "        loss = mse(true_out_state[-1],pred_out_state[-1])\n",
    "        #loss = mse(true_out_state,pred_out_state)\n",
    "        #loss.backward(retain_graph=True)\n",
    "        #optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        tot_loss+=loss\n",
    "        \n",
    "    temp_tot_loss = sum(loss_list)\n",
    "    temp_tot_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_list = [round(float(temp_loss.detach()),3) for temp_loss in loss_list]\n",
    "    return tot_loss,loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playthrough(res,file_num):\n",
    "    \n",
    "    global steps, num_channels, inp_channels, tau, model, optimizer\n",
    "    \n",
    "    PATH1 = \"models\\\\\"+str(file_num)+\"_height_model.pt\"\n",
    "    PATH2 = \"models\\\\\"+str(file_num)+\"_width_model.pt\"\n",
    "    \n",
    "    height_model = torch.load(PATH1)\n",
    "    width_model = torch.load(PATH2)\n",
    "    \n",
    "    mse = nn.MSELoss()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_list = []\n",
    "    tot_loss = 0\n",
    "    pred_final_list = []\n",
    "    for trial in range(len(res['train'])):\n",
    "        \n",
    "        temp_choice = np.random.choice([0,1],1,p=[1.0,0.0])\n",
    "        temp_dict = {0: get_inp_state,1: get_ran_init_state}\n",
    "        \n",
    "        state_inp,inp_height,inp_width = temp_dict[temp_choice[0]](trial,res,inp_channels)\n",
    "        \n",
    "        #get predicted output height\n",
    "        inp_height_tensor = torch.FloatTensor([inp_height])\n",
    "        out_height = torch.round(height_model(inp_height_tensor))\n",
    "        out_height = int(out_height)\n",
    "        \n",
    "        #get predicted output width\n",
    "        inp_width_tensor = torch.FloatTensor([inp_width])\n",
    "        out_width = torch.round(width_model(inp_width_tensor))\n",
    "        out_width = int(out_width)\n",
    "        \n",
    "        num_inp = out_height*out_width\n",
    "        \n",
    "        #run \n",
    "        state_inp = torch.FloatTensor(state_inp)\n",
    "        temp_state = init_state(state_inp,num_channels,out_height,out_width,inp_height,inp_width,inp_channels)\n",
    "        for step in range(steps):\n",
    "            net_inp = perception(temp_state,num_channels-inp_channels)\n",
    "            net_inp = torch.transpose(net_inp, 0, 3)\n",
    "            net_inp = torch.transpose(net_inp, 1, 2)\n",
    "            net_inp = net_inp.reshape((num_inp,num_channels*3))\n",
    "\n",
    "            state_update = model(net_inp)\n",
    "\n",
    "            state_update = state_update.view((out_width,out_height,1,num_channels))\n",
    "            state_update = torch.transpose(state_update, 1, 2)\n",
    "            state_update = torch.transpose(state_update, 0, 3)\n",
    "            state_update = stochastic_update(temp_state,state_update,inp_channels,out_height,out_width,out_channels)\n",
    "            temp_state = state_update\n",
    "            \n",
    "        #get losses\n",
    "        true_out_state,out_height,out_width = get_out_state(trial,res,out_channels)\n",
    "        true_out_state = torch.FloatTensor(true_out_state)\n",
    "\n",
    "        pred_out_state = temp_state[num_channels-out_channels:num_channels].view(out_channels,out_height,out_width)\n",
    "        print(pred_out_state.shape)\n",
    "        print(torch.round(pred_out_state[-1].detach()).numpy())\n",
    "        pred_out_state = F.softmax(pred_out_state,0)\n",
    "        #print(true_out_state.shape)\n",
    "        #print(temp_state.shape)\n",
    "        #print(pred_out_state.shape)\n",
    "        loss = mse(true_out_state[-1],pred_out_state[-1])\n",
    "        tot_loss+=loss\n",
    "\n",
    "        #convert tensor to standard output\n",
    "        org_shape = pred_out_state.shape\n",
    "        \n",
    "        #get list of symbols\n",
    "        inp_set = [i for i in range(10)]\n",
    "        \n",
    "        #turn one-hot into symbols tensor\n",
    "        \n",
    "        pred_out_state = temp_state[1+num_channels-out_channels:num_channels].view(out_channels-1,out_height,out_width)\n",
    "        pred_out_state = F.softmax(pred_out_state,0)\n",
    "        pred_out_state = torch.transpose(pred_out_state, 0, 1)\n",
    "        pred_out_state = torch.transpose(pred_out_state, 1, 2)\n",
    "        #print(pred_out_state.shape)\n",
    "        #print(\"{} vs {}\".format(out_height,out_width))\n",
    "        temp_final = torch.zeros((out_width,out_height))\n",
    "        count1 = -1\n",
    "        for row in pred_out_state:\n",
    "            count1+=1\n",
    "            count2 = -1\n",
    "            for col in row:\n",
    "                count2+=1\n",
    "                num = torch.argmax(col)\n",
    "                temp_final[count1][count2] = inp_set[num]  \n",
    "        pred_final = torch.transpose(temp_final, 0, 1)\n",
    "        true_final = torch.FloatTensor(res['train'][trial]['output'])\n",
    "        if(torch.all(torch.eq(pred_final, true_final))):\n",
    "            print(\"------------True-------------\")\n",
    "        else:\n",
    "            print(\"False:  {}   {}  {} -------\".format(pred_final.shape,true_final.shape,pred_final.shape==true_final.shape))\n",
    "        \n",
    "        print(\"Loss: {}\".format(loss))\n",
    "        pred_final_list.append(pred_final)\n",
    "    return tot_loss,pred_final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "state_pred_epochs = 3000\n",
    "out_pred_epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(directory)\n",
    "directory = 'abstraction-and-reasoning-challenge\\\\training\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = -1\n",
    "for filename in dir_list:\n",
    "    file_num+=1\n",
    "\n",
    "    if(file_num<4):\n",
    "        continue\n",
    "    \n",
    "    f = open(directory+filename, \"r\")\n",
    "    data = f.readlines()\n",
    "    data = data[0]\n",
    "    res = json.loads(data)\n",
    "    \n",
    "    #define channel sizes\n",
    "    inp_channels = 11\n",
    "    inf_channels = 4\n",
    "    out_channels = 11\n",
    "    num_channels = inp_channels + inf_channels + out_channels\n",
    "    \n",
    "    #define models\n",
    "    \n",
    "        \n",
    "    model = big_NN(num_channels)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    tau = .01\n",
    "    \n",
    "    print(\"--------------------New File: {}--------------------\".format(file_num))\n",
    "    print(\"--------output length model--------\")\n",
    "    #train output length prediction model\n",
    "    tot_loss1, tot_loss2 = run_out_pred(res,file_num,out_pred_epochs)\n",
    "    print(\"loss1: {}  loss2: {}\".format(tot_loss1,tot_loss2))\n",
    "    while(tot_loss1>.0001 or tot_loss2>.0001):\n",
    "        tot_loss1, tot_loss2 = run_out_pred(res,file_num,out_pred_epochs)\n",
    "        print(\"loss1: {}  loss2: {}\".format(tot_loss1,tot_loss2))\n",
    "        \n",
    "    print(\"--------state prediction model-----\")\n",
    "    \n",
    "    PATH1 = \"models\\\\\"+str(file_num)+\"_height_model.pt\"\n",
    "    PATH2 = \"models\\\\\"+str(file_num)+\"_width_model.pt\"\n",
    "\n",
    "    # Load\n",
    "    height_model = torch.load(PATH1)\n",
    "    width_model = torch.load(PATH2)\n",
    "    \n",
    "    #train state prediction model\n",
    "    for epoch in range(state_pred_epochs):\n",
    "        tot_loss,loss_list = run(res,file_num)\n",
    "        print(\"epoch {}  loss: {}: loss_list: {}\".format(epoch,tot_loss,loss_list))\n",
    "        if(tot_loss<.0005):\n",
    "            break\n",
    "    \n",
    "    playthrough(res,file_num)\n",
    "    \n",
    "    PATH = \"models\\\\\"+str(file_num)+\"_model.pth\"\n",
    "    torch.save(model, PATH)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    \n",
    "def plot_pictures(pictures, labels):\n",
    "    fig, axs = plt.subplots(1, len(pictures), figsize=(3*len(pictures),32))\n",
    "    for i, (pict, label) in enumerate(zip(pictures, labels)):\n",
    "        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n",
    "        axs[i].set_title(label)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_sample(sample, predict=None):\n",
    "    if predict is None:\n",
    "        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n",
    "    else:\n",
    "        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = 1\n",
    "temp_filename = os.listdir(directory)[file_num]\n",
    "f = open(directory+filename, \"r\")\n",
    "print(temp_filename)\n",
    "data1 = f.readlines()\n",
    "data1 = data1[0]\n",
    "res1 = json.loads(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"models\\\\\"+str(file_num)+\"_model.pth\"\n",
    "#model = torch.load(PATH)\n",
    "loss,pred_final = playthrough(res1,file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 0\n",
    "plot_sample(res['train'][sample_num],pred_final[sample_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_final[sample_num].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to convert this back to numbers\n",
    "inp_state,height,width = get_inp_state(sample_num,res,inp_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inp_state[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_state,height,width = get_out_state(sample_num,res,inp_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_state[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
